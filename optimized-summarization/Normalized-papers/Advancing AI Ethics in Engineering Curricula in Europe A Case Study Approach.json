{
  "title": "Advancing AI Ethics in Engineering Curricula in Europe: A Case Study Approach",
  "sections": [
    {
      "title": "Abstract",
      "content": "The Erasmus+ Ethical Engineer project aims to enhance AI education by integrating ethical, social, and legal aspects into engineering training, promoting truthful AI in Europe. In the paper, we present the explored case studies and the methodology for their development. AI ethics is explored through the following case studies. AI in healthcare is examined through fall detection systems for vulnerable populations, the potential for data bias in personalized medical devices, and the ethical implications of off-label device use, such as continuous artificial hearts. The use of AI in witness testimonies is considered through the example of the AIWitness chatbot designed to automate witness statements. Ethical considerations surrounding facial recognition are explored in the context of airport boarding, using a hypothetical scenario based on Brighton International Airport's pilot program, FaceBoard. The project also considers self-driving taxis' ethical and practical implications, using a hypothetical scenario in San Francisco. The ecological impact of generative AI is analyzed, referencing studies from Stanford University on energy consumption and water usage for cooling systems. The ethical challenges of AI in marketing processes are addressed, including the generation of content like text, images, and voice, along with concerns about job displacement, fake content creation, and authorship issues. The use of AI in assessing historic photos is examined, focusing on selection bias, the potential for surfacing insulting content, the need for transparency, and the potential prioritization of profit over ethical considerations. Finally, the paper addresses the pervasive issue of bias in data, particularly within the field of data science. The main contribution of the paper is the development of a structured template for creating AI ethics case studies, which we already tested with smaller groups of teachers and students and refined based on their feedback."
    },
    {
      "title": "INTRODUCTION",
      "content": "At its core, the engineering profession is not only focused on applying technical knowledge. It has been for many decades, even centuries, focused on the ethical application of knowledge. Recently, this distinction has become of utmost importance, particularly in the rapidly evolving landscape of artificial intelligence (AI) and its widespread applications in all aspects of human life. While technical proficiency remains essential, the societal impact of engineering decisions has never been more profound, demanding a heightened awareness of ethical responsibilities , . Consequently, engineering ethics is no longer a theoretical exercise but a vital, practical academic discipline that prepares students to navigate complex real-life situations.\nTraditionally, engineering ethics education has focused on core principles such as safety, honesty, and fairness. The reason was the straightforwardness of the engineering work and technical solutions and the focus on the profession. However, the development and application of AI has introduced a new layer of complexity. With their capacity for autonomous decision-making and data-driven insights, AI systems often operate in opaque ways, making it challenging to trace accountability or foresee unintended consequences. This opacity amplifies the ethical dimensions of engineering practice, necessitating a more subtle understanding of issues like algorithmic bias, data privacy, and the potential for unintended discrimination of different social groups.\nEngineering students must be equipped to evaluate the ethical implications of their work critically. This includes understanding the technical aspects of AI systems and developing the ability to assess their societal impact. They must identify potential ethical dilemmas, weigh competing values, and make informed decisions prioritizing human well-being and societal good.\nThe traditional view of an engineer as a neutral technician is no longer durable. Engineers actively shape the world, and their decisions have far-reaching consequences. For example, an engineer designing a facial recognition system must consider the potential for misuse, the impact on privacy, and the risk of discriminatory outcomes. Similarly, an engineer developing an AI-powered medical diagnostic tool must know the potential for data bias and the consequences of inaccurate diagnoses. Furthermore, the responsibilities of engineers are becoming increasingly complex due to the global nature of technology and the interconnectedness of systems. Engineers often work in multidisciplinary teams, collaborating with professionals from diverse backgrounds. This requires them to communicate effectively, understand different perspectives, and navigate potential conflicts of interest.\nEngineering ethics education must adapt to these evolving realities. It must move beyond abstract principles and focus on practical skills, such as ethical reasoning, critical thinking, and communication. Case studies, simulations, and realworld initiatives and projects can allow students to apply ethical principles in realistic scenarios. Giving students the opportunity during their education to recognize the broader social, political, economic and ethical impacts of the profession -through multimedia simulation, role-playing games, case-based learning, and review of other, fictionalized cases -can give them opportunities to reflect on the need to identify complex situations in future settings, as well as a safe environment in which to explore, make mistakes, and discuss the ramifications of various decisions in authentic contexts ."
    },
    {
      "title": "OBJECTIVES FOR ETHICAL INSTRUCTION IN ENGINEERING",
      "content": "AND AI EDUCATION A search in the literature shows that engineering ethics have been in place for many decades, and education plays a vital role in its formation and reshaping. Objectives for engineering ethics education were formulated in literature.\nOne of the specifications that corresponds with our project is by B. Newberry : stimulate the ethical imagination of students; teach students to recognize ethical issues; support students analyze key ethical concepts and principles; help students deal with ambiguity; encourage students to take ethics seriously; increase student sensitivity to ethical issues; increase student knowledge of relevant standards; improve ethical judgment; foster ethical willpower. The objectives outlined by Newberry align well with the goals of our project, emphasizing the importance of promoting ethical sensitivity, analytical skills, and moral responsibility among students. Integrating these principles into engineering education makes it possible to prepare future engineers better to navigate ethical dilemmas and uphold professional integrity in their careers.\nIn the context of artificial intelligence, these objectives for ethical instruction in engineering education take on a heightened significance, demanding a tailored approach to prepare students for the unique challenges posed by AI's rapid advancement. 4. To help students deal with ambiguity in AI ethics, educators should present complex case studies with no easy answers, simulating real challenges that might occur. This involves exploring scenarios where ethical principles clash, data is incomplete or biased, and the long-term consequences are uncertain. Students must develop the capacity to make reasoned judgments in the face of ambiguity and to articulate their reasoning clearly."
    },
    {
      "title": "5.",
      "content": "To encourage students to take ethics seriously in the context of AI, the curriculum should demonstrate the real-world consequences of unethical AI development. This can be achieved through case studies of AI failures, discussions of ethical breaches in the tech industry, and engagement with current debates surrounding AI regulation and policy.\nTo increase student sensitivity to ethical issues related to AI, instruction should emphasize empathy and perspective-taking. Students must learn to consider the impact of AI systems on diverse populations, including marginalized groups, and recognize the potential for AI to exacerbate existing inequalities."
    },
    {
      "title": "7.",
      "content": "To increase student knowledge of relevant standards in AI ethics, educators should familiarize students with emerging ethical guidelines, codes of conduct, and regulatory frameworks. This includes exploring initiatives such as the EU AI Act , the IEEE Ethically Aligned Design , and the work of various AI ethics research centers.\nTo improve ethical judgment in AI engineering, the curriculum should allow students to apply ethical principles in practical scenarios. This can involve simulations, role-playing exercises, and real-world projects that require students to make moral decisions in the context of AI development."
    },
    {
      "title": "9.",
      "content": "To promote ethical willpower in the face of pressures to prioritize profit or expediency, educators should foster a culture of moral leadership and encourage students to speak up when they witness unethical behavior. This involves creating a safe space for students to discuss ethical concerns and to develop the confidence to advocate for responsible AI development."
    },
    {
      "title": "DESIGN OF CASE STUDIES",
      "content": "Our prior work outlined a foundational approach for creating case studies. Building on this, we developed a structured template along with guidelines for designing them.\nThe introduction presents the scenario, emphasizing critical ethical issues in AI, followed by relevant background information. This section provides necessary technical and situational information for students to understand the case, including the AI approach used in question and how it is used. Then, the narrative section describes real-life examples and/or studies highlighting how AI is already used in the real world or is likely to be used shortly. Characters and roles are introduced to personalize the ethical dilemmas. These stakeholders in the case reflect different opinions, dilemmas, and interests in the AI application. They can have overlapping opinions and motives, and they might shirk or be parallel or outright contradictory. However, what we want to avoid is \"right\" vs. \"wrong\" opinions. Students must learn how to weigh and balance various implications in a structured manner.\nThe next part is devoted to articulating ethical dilemmas or issues at hand. Each character/role looks at the AI from his/her angle, and we expect that most have noble intentions. However, each angle has pros and cons. This part should help students realize that AI solutions built for the best reasons can have unintended consequences. The narrative section is followed by the section Ethical Considerations, which identifies discussion points (specific ethical principles or theories that apply), diverse perspectives (multiple viewpoints, including potential benefits and harms), discussion points for during the meeting (do we wish to present various ethical considerations, or do we also want to include how various ethical scholars/frameworks would approach the ethical dilemmas; each session can look at different frameworks and apply them to the case). The last section presents open-ended questions to encourage critical thinking and discussion. The recommendation also formulates the learning objectives of the case studies, i.e., what the students should take from the lessons. The basic items are understanding ethical frameworks, critical thinking, awareness of the impact, decision-making skills, global and cultural perspectives, responsibility, and accountability. Last but not least, the recommendation contains advice on using the case studies in a teaching environment. The basic activities are group discussions, role-playing and debates, reflective writing, and discussions with guest speakersindustry experts and/or ethicists.\nThe rest of this section is devoted to a brief description of our developed case studies. We tried to identify topics from various application domains to show the diversity of the problems and approaches to their analysis.\nCase study AI in healthcare. By 2050, the global elderly population is projected to increase from 8.5% to 20% , driving demand for AI-driven fall detection systems. These systems integrate AI and sensor technologies to monitor movement and detect falls, enabling real-time alerts that facilitate immediate caregiver response and potentially prevent severe injuries or fatalities. By accelerating intervention, this technology enhances care quality and reduces hospitalizations, mitigating risks associated with prolonged immobility, such as dehydration, hypothermia, bronchopneumonia, and pressure sores . However, potential shortcomings include privacy risks, data security concerns, and challenges in ensuring system reliability in practical applications .\nCase study AI in witness testimonies: AI applications in forensic sciences are already in practice , and proponents argue they may create a fairer, more objective legal system by reducing human bias . However, the stakes of deploying AI in this context are substantial. Concerns include privacy, accuracy, and AI's influence on legal decisionmaking. A key risk is false memory formation, as generative chatbots have been shown to induce over three times more immediate false memories than control methods, with effects persisting after one week . This case study, building upon readily existing AI witness testimonial technology, hypotheses the consequences of such applications.\nCase study AI in facial recognition. Facial recognition technology, a subset of computer vision, identifies individuals based on facial features. This technology, a subset of computer vision, has seen rapid advancement and increasing adoption in various sectors, including aviation. Airports utilize this technology to streamline boarding and enhance security, while governments deploy it at border crossings to improve surveillance and mitigate security threats. In , Almeida et al. write on governments using it at border controls and that governments and private entities use it at airports. Not explicitly that they do it to streamline boarding, nor enhancing security. That part stems from our own case). However, its use raises significant concerns. The handling of sensitive biometric data presents risks such as data breaches and potential misuse of personal information . While it enhances efficiency and security, its implications for privacy and data protection remain a subject of debate.\nCase study AI in self-driving taxis. This development promises technological innovation, reduced congestion, and improved accessibility . However, it raises critical ethical concerns, including public safety, job displacement, and societal impact.\nCase study GenAI´s ecological impact. The rapid development of AI generative models, such as GPT-4, has revolutionized how we interact with technology, offering significant productivity gains , across various sectors, including education. These models can produce coherent text, generate creative content, and assist in complex problem-solving. However, their development and deployment raise significant ecological concerns regarding energy and water consumption . This case study explores the balance between the productivity gains from generative models and their environmental impact.\nCase study AI in marketing processes. To some marketing professionals, AI has been a great help, especially those working for many clients and managing their social media accounts and posting content daily, for several reasons such as writing text, explaining the product from a technical standpoint, generating ideas, creating unique and highquality images for social media posts and many other reasons explained further in the case study. However, while some marketing professionals see AI as a helpful tool, others see it as something that will take away their jobs and make them irrelevant in the modern marketing world. A study by the McKinsey Global Institute estimates that by 2030, automation could displace up to 800 million jobs, with 375 million workers needing substantial retraining). As technology is improving and becoming even more advanced, young people are understandably worried about their freelancer jobs in the field of marketing because small companies can now use AI tools provided by tech companies to save costs on hiring marketing professionals as freelancers, which could mean that young people would struggle even more to find jobs and unemployment among the younger generation would be even higher.\nCase study AI in assessing historic photos. Some companies are using AI to learn what is currently widespread and ongoing in society worldwide, thus predicting what will be profitable for a particular company to promote and sell goods and services. In many cases, AI's training data is the whole internet, which could be problematic because on the internet, aside from valuable information, one can also find offensive, racist, and sexist material, where inappropriate content is often amplified and normalized. There are ethical concerns about how artificial intelligence will distinguish \"right\" from \"wrong,\" and \"appropriate\" from \"inappropriate.\" What is racist, and what is sexist? What about ambiguous social concepts such as cultural appropriation (when members of a majority group adopt cultural elements of a minority group in an exploitative, disrespectful, or stereotypical way), which is a very debatable issue in many cases? Another issue in this regard is the historical context. How will AI consider the historical context, the setting in which a historical event, idea, or object takes place, and includes the social, economic, cultural, and political influences that shape the idea or the event?\nCase study Continuous artificial heart -off-label use device in medicine. Mechanical circulatory support (MCS) refers to a range of devices used to assist or replace the heart's function in patients with severe cardiac conditions, typically those with heart failure. There are several mechanical circulatory support systems, including total artificial heart (TAH) and ventricular assist device (VAD) . Both of these devices are FDA-approved (FDA -U.S. Food and Drug Administration). Continuous flow total artificial heart (CFTAH) consists of two continuous ventricular assist devices that produce non-pulsatile blood flow (or continuous blood flow) into both systemic and pulmonary circulation. This device does not have FDA approval. It works as an \"off-label use device\". The controversy surrounding non-pulsatile blood flow in the human body primarily stems from concerns about how continuous blood flow may affect the body's organs, tissues, and overall vascular health. The off-label use of medical devices, where a device is used in a way not explicitly approved by regulatory agencies (like the FDA in the U.S.), presents several ethical challenges. These moral issues arise from balancing patient benefits with safety, informed consent, and regulatory adherence.\nCase study One pulsatile heart pump size does not fit all patients. The first-generation ventricular assist devices (VAD) systems for adult patients relied on volume displacement pumps with one constant stroke volume for all sizes of patients. The concept of one size of medical device for all patients goes against the principle of personalized medicine. Personalized medicine emphasizes the importance of tailoring the size and design of these devices to patients' individual needs. The use of one standard-size pump can lead to suboptimal outcomes , . Factors such as body size, and specific medical conditions must be considered when selecting a heart pump. The mismatch between the device size and the patient's physiological requirements can result in complications such as non-physiological blood flows and pressure or inefficient circulatory support. The issues are particularly critical in patients with unique anatomical features or extreme body sizes. By adopting a personalized approach, clinicians can improve the effectiveness and safety of treatment while reducing the risk of complications.\nCase study AI in data analytics (Data Science). During the last decade, we have witnessed explosive growth in the data science discipline. It mainly applies advanced AI methods for analyzing enormous data volumes (big data). The key developments are connected with increased computational power that allows complex computations. One of the rapidly advancing subfields of machine learning is deep learning, which relies on multi-layered neural networks. This approach has led to numerous sophisticated and impactful applications across various domains. Notable examples include selfdriving vehicles, advanced medical diagnostics, and personalized recommendation systems. Additionally, deep learning has played a significant role in COVID-19-related data analysis, including outbreak prediction, diagnostics through image analysis, drug discovery, and monitoring public sentiment on social media-particularly in tracking the spread of misinformation . However, the influence of data analytics extends beyond positive applications, as demonstrated by the Cambridge Analytica case , , which highlights ethical concerns regarding data misuse. These developments illustrate how data-driven technologies can shape decision-making processes, public opinion, and societal structures , underscoring both their potential benefits and ethical challenges.\nCase study Bias in data. The problem of bias in data refers to systematic errors or distortions presented in data, leading to unfair or inaccurate conclusions when the data is analyzed or used to train machine learning models , . These biases can arise from various sources and have significant consequences, especially in decision-making processes affecting people's lives. With the ease of collecting large data volumes, the need for proper checking of input data increases. It is necessary to understand the origin, nature, and content of the data to be used to develop AI models for which, more and more frequently, machine learning, in particular deep learning algorithms, are applied. Now, let us focus on key aspects of data bias and its consequences. There are several main sources of bias in data. Sampling bias occurs when the data collected does not represent the population it is intended to convey. Selection bias arises when the process of selecting data for analysis is not random or objective. Measurement bias occurs when the way data is measured or collected introduces systematic errors. Confirmation bias is a cognitive bias where people seek out and interpret information confirming their beliefs, leading to biased data collection or analysis. Historical bias reflects existing societal inequalities and prejudices embedded in historical data and narratives. Algorithmic bias occurs when the algorithms used to analyze data or train machine learning models introduce bias (usually due to primarily using biased data for training the algorithm)."
    },
    {
      "title": "EXAMPLE OF A CASE STUDY",
      "content": "Here we present one example of a developed case study following the structured template. On the case study of AI in facial recognition we show the content and proposed graphical layout. The case studies are described in a condensed form with the main points highlighted. This paper describes the fundamental objectives for ethical instruction in engineering education in the context of artificial intelligence. In the frame of the Erasmus+ project Ethical Engineer, we proposed a scheme and recommendation for developing case studies. In the Introduction, the scenario, highlighting key ethical concerns in AI, is described, followed by background information that provides necessary technical and situational information for students to understand the case, including the AI approach used in question and how it is used. The Narrative section describes real-life examples and/or studies highlighting how AI is already used in the practice or is likely to be used soon. Section Ethical considerations identifies discussion points and diverse perspectives, followed by open-ended questions for critical thinking and discussion are presented. The final part is constituted by recommendations to the teachers, particularly the learning objectives of the case studies and advice on how to use the case studies in the teaching environment. With the help of this template and recommendation, we developed a series of case studies in which we tried to cover a larger variety of examples from different areas of real life. Some of them were already used in the teaching process, and after discussion with students, the background information part and the open-ended questions were modified (extended). The development is not finished yet because we plan more thorough testing with teachers and students in the next academic year."
    }
  ]
}