{
  "title": "Ethical AI: Towards Defining a Collective Evaluation Framework",
  "sections": [
    {
      "title": "Abstract",
      "content": "Artificial Intelligence (AI) is transforming sectors such as healthcare, finance, and autonomous systems, offering powerful tools for innovation. Yet its rapid integration raises urgent ethical concerns related to data ownership, privacy, and systemic bias. Issues like opaque decision-making, misleading outputs, and unfair treatment in high-stakes domains underscore the need for transparent and accountable AI systems. This article addresses these challenges by proposing a modular ethical assessment framework built on ontological blocks of meaning-discrete, interpretable units that encode ethical principles such as fairness, accountability, and ownership. By integrating these blocks with FAIR (Findable, Accessible, Interoperable, Reusable) principles, the framework supports scalable, transparent, and legally aligned ethical evaluations, including compliance with the EU AI Act. Using a real-world use case in AI-powered investor profiling, the paper demonstrates how the framework enables dynamic, behavior-informed risk classification. The findings suggest that ontological blocks offer a promising path toward explainable and auditable AI ethics, though challenges remain in automation and probabilistic reasoning."
    },
    {
      "title": "INTRODUCTION",
      "content": "Artificial Intelligence (AI) has emerged as a transformative technology, revolutionizing fields such as healthcare, finance, and autonomous systems. While AI offers significant benefits, including enhanced productivity and innovative solutions to global challenges, its rapid evolution also introduces profound ethical challenges that require immediate and thorough attention.\nOne of the foundational challenges lies in the data used to train AI systems. AI relies heavily on vast datasets sourced from the internet, private organizations, and other repositories. However, issues related to data ownership, consent, and privacy remain unresolved. Questions such as \"Who owns the data?\" and \"Was it ethically obtained?\" highlight potential risks of misuse and exploitation, raising concerns about intellectual property rights and individual privacy.\nAnother pressing issue is trustworthiness. AI systems occasionally produce misleading or incorrect outputs, a phenomenon known as \"hallucinations.\" Moreover, ensuring the safety of AI systems and maintaining detailed records of their decision-making processes are critical for fostering trust. Without robust mechanisms for safety and accountability, reliance on AI systems could lead to unforeseen risks, particularly in high-stakes domains such as healthcare, finance, and law enforcement.\nHowever, the most profound challenges arise from the ethical implications of AI's outcomes. AI systems, often operating as \"black boxes\", generate decisions and recommendations with far-reaching consequences. The absence of embedded ethical considerations can result in biased, unfair, or even harmful outcomes. For example:\n• Biased algorithms in hiring or lending processes can perpetuate societal inequalities. • Unethical use of AI in surveillance can infringe on civil liberties. • Lack of explainability can erode trust, particularly in lifecritical applications. Addressing these challenges requires a collaborative effort among technologists, policymakers, ethicists, and the public. Establishing robust frameworks for ethical AI development and deployment is imperative to ensure AI aligns with human values and serves humanity equitably and responsibly."
    },
    {
      "title": "Key Ethical Challenges in AI",
      "content": "• Data-Related Issues: These include questions around data accuracy, inclusion of purposefully misleading data or even data poisoning • Trustworthiness: AI systems must be reliable, safe, and explainable to avoid risks like hallucinations and over reliance on black-box outcomes. • Ethical Implications of Outcomes: The potential for biased or harmful decisions underscores the need to embed ethical principles directly into AI systems. As AI continues to integrate into society, the task of addressing these ethical dilemmas grows increasingly complex. While the challenges are significant, they also present an opportunity to build a future where AI aligns with the highest ethical standards. By fostering collaboration and establishing comprehensive frameworks, we can ensure that AI development progresses in a way that prioritizes transparency, fairness, and accountability.\nThe article is organized in five sections: Introduction (Section I), background (Section II), literature review (Section III), methodology and discussion (Section IV), then includes conclusion and recommendations (Section V)."
    },
    {
      "title": "BACKGROUND",
      "content": "Ethical AI refers to the development and deployment of artificial intelligence systems that emphasize fairness, transparency, accountability, and respect for fundamental rights . AI ethics emphasises the impact of AI on individuals, groups and wider society. The goal is to promote safe and responsible AI use, to mitigate AI's novel risks and prevent harm. Much of the work in this area centres around four main verticals: Frameworks such as the six core principles of the WHO , the EU AI Act highlight the importance of protecting autonomy, promoting equity, and fostering responsibility. Despite these efforts, ethical frameworks often lack technical grounding and do not address the dynamic nature of AI systems , - .\nFor example, Reinforcement-Learning (RL), particularly deep reinforcement learning, operates as a closed-box system, posing challenges in explainability - . Human-in-theloop (HITL) AI approaches provide a potential solution by integrating human oversight at critical stages, but their implementation in Self Reinforcement Learning (SLR) remains limited.\nRecent studies highlight several state-of-the-art advances in ethical AI and SRL. Mehrabi et al. explore bias mitigation techniques such as data cleaning, model adjustments, and output tuning. , discusses interpretability approaches such as SHAP and LIME, which enhance explainability in complex models. Human-in-the-loop systems integrate ethical oversight effectively, while the EU AI Act offers risk-based regulations tailored for high-stakes applications."
    },
    {
      "title": "Objectives",
      "content": "This article addresses key challenges in ethical AI and aims to:\nPropose a unified system for monitoring AI outcomes in line with the EU AI Act and emerging global regulations. 2) Evaluate the feasibility of using ontological blocks of meaning for ethical assessment. 3) Explore the integration of FAIR (Findable, Accessible, Interoperable, Reusable) principles into these ontological blocks. Together, these objectives support the development of ethical AI frameworks that promote transparency, accountability, and fairness ."
    },
    {
      "title": "LITERATURE REVIEW",
      "content": "The rising importance of ethical Artificial Intelligence (AI) has driven researchers and institutions to develop frameworks, methods, and applications that promote transparency, accountability, and fairness. This review is organized into subsections covering finance, healthcare, autonomous vehicles, ontological and FAIR approaches, and global initiatives."
    },
    {
      "title": "Ethical AI in Finance",
      "content": "AI-driven credit scoring in finance raises ethical concerns about bias and unequal treatment.\n• Hassani shows how societal biases in training data reinforce discrimination in credit assessments, disproportionately affecting marginalized groups.\n• Packin warns that lack of comprehensive data on disabled individuals can lead to exclusionary outcomes in AI-based scoring. Identified Gap: Independent tools like ontological blocks are proposed to detect and mitigate embedded bias in financial AI systems."
    },
    {
      "title": "Ethical AI in Healthcare",
      "content": "Healthcare-particularly oncology-illustrates the need for ethical AI frameworks to safeguard privacy, transparency, and fairness .\n• Ontological blocks have been applied to sensitive patient data under FAIR principles, aiding in personalized treatment planning , . • Monteith et al. caution against misinformation in AI mental health tools, stressing the need for explainability and oversight. • Antoniou et al. highlight the need for explainable AI to manage complex diagnoses involving comorbidities. Identified Gap: Real-time, scalable use of explainable AI methods (e.g., SHAP, LIME) remains a key challenge in highstakes clinical settings ."
    },
    {
      "title": "Ethical AI in Autonomous Vehicles",
      "content": "Autonomous vehicles demand AI systems that prioritize safety, accountability, and ethical reasoning.\n• Lin and Jenkins et. al. examines scenarios like the trolley problem, calling for transparent ethical decision-making in critical moments. • Goodall advocates for programming rules that minimize harm during unavoidable accidents. • Nyholm and Smids argue for clear accountability frameworks among manufacturers, users, and regulators. Identified Gap: Ensuring real-time ethical decisions and system adaptability remains a core technical and ethical challenge."
    },
    {
      "title": "Ontological and FAIR Approaches for Ethical AI",
      "content": "Ontological models and FAIR principles are emerging as foundational tools for ethical AI design.\n• Ontological blocks, drawing from Semantic Web standards , , provide scalable representations of principles like non-maleficence and equity . • FAIR principles -Findable, Accessible, Interoperable, and Reusable-support the openness and standardization of ethical modules. • Guizzardi et al. emphasize the need for ontologies that model user-centric concerns like privacy, fairness, and risk.\nChallenges: Implementing FAIR-aligned ontological blocks is constrained by the manual effort needed to build and maintain interoperable frameworks."
    },
    {
      "title": "Global and Collaborative Efforts",
      "content": "International collaborations aim to mitigate societal-scale risks and build governance frameworks for ethical AI , , .\n• The EU champions \"ethics-by-design,\" embedding ethics at the development stage . • An international consortium proposes benchmarking societal risks, promoting transparency and cooperative oversight .\n• Responsible Research and Innovation (RRI) offers a governance model that aligns AI with societal values - . Future Direction: These efforts underscore the importance of global standards and shared accountability mechanisms for ethical AI deployment."
    },
    {
      "title": "METHODOLOGY AND DISCUSSION",
      "content": ""
    },
    {
      "title": "Methodology",
      "content": "This article uses descriptive research and qualitative observation to explore ethical AI pathways. Key variables include: Ethical outcomes -Benchmarks set by experts in ethics, AI, and policy; Verification -Methods to automate assessments against benchmarks; Scalability -Applicability across varied AI systems and domains.\nRather than conducting empirical simulations, the study synthesizes literature, expert insights, and theoretical models to propose actionable frameworks."
    },
    {
      "title": "Flexibility Requirements for an Ethical AI",
      "content": "Integrating ethical AI into legally binding decisions requires acknowledging that legal standards vary significantly by context. Ethical and legal thresholds are not fixed; they shift based on specific circumstances and competing interests. Therefore, ethical AI systems must be adaptable, aligning with legal norms while upholding fairness and accountability.\nFor example, in serious criminal investigations like murder, authorities may justifiably relax privacy protections to prioritize truth-seeking over individual rights. In contrast, financial transactions-such as a custodian bank managing client funds-demand stricter ethical and legal adherence, emphasizing fiduciary duty over operational flexibility. These scenarios highlight the need for dynamic ethical standards that adjust to context.\nThis variability challenges the one-size-fits-all ethics frameworks found in much of the AI literature, which often overlook the contextual nature of legal and ethical reasoning. An AI system cannot apply identical principles to a police investigation and a banking transaction, given their differing priorities and risks.\nWe propose a flexible, modular framework based on ontological blocks of meaning-discrete ethical principles that can be layered or combined. This allows AI systems to dynamically tailor their ethical reasoning to specific legal domains. For instance, an AI analyzing financial data might prioritize fiduciary responsibility, while one used in criminal justice may focus on due process. Such a system ensures ethical adaptability, legal alignment, and transparent oversight."
    },
    {
      "title": "Ontological Blocks of Meaning",
      "content": "Ontology-the philosophical study of definitions-offers a foundation for aligning human ethical concepts with AI systems. Just as the concept of light evolved from Newtonian particles to quantum duality, terms like responsibility or ownership must be redefined for AI interpretation while preserving their ethical core.\nIn AI ethics, this means translating abstract ethical terms-right, wrong, ownership, responsibility-into constructs that AI can process. These must be both philosophically robust and operationally viable. Ontological blocks are modular, structured representations of ethical principles that can be integrated into AI operations. Creating them involves: Translating ethical concepts into machine-readable constructs; Embedding them into modular, systematic representations; Preserving ethical meaning while ensuring scalability and precision.\nThis ensures AI systems align with human values while providing a functional, auditable ethical framework.\nPractically, creating ontological blocks involves developing a structured system to categorize ethical principles, values, and guidelines. Drawing from ontological practices in fields like oncology-e.g., the Cancer Care Treatment Outcome Ontology and the NCI Thesaurus , -this process starts by defining core ethical dimensions such as fairness, accountability, and transparency, and mapping them to relevant AI domains.\nCollaboration with domain experts ensures term accuracy and contextual relevance. Ethical AI frameworks such as those by Prem support alignment with current standards. Recent models like the Ontology for Ethical AI Principles (AIPO) use vocabularies such as Dublin Core, SKOS, FOAF, and DCAT2 to generate dynamic knowledge graphs, enabling semantic querying and systematic analysis . These approaches support transparency, consistency, and accountability in ethical AI development."
    },
    {
      "title": "Designing Ontological Blocks for Algorithmic Use",
      "content": "Ontological blocks translate ethical concepts into structured, quantifiable forms. For instance, defining \"stealing is bad\" involves breaking it down into core concepts like property and ownership.\nExample: A dataset element (e.g., a car) represents property, while ownership (e.g., \"Tom owns the car\") provides context. Generalization: Instead of rule-based examples, AI evaluates principles of ownership, avoiding reliance on predefined scenarios. Incomplete data: AI may infer missing elements through cross-referencing. If cross-references are weak, human oversight is required. Short format: The point of the ontological block is that it would refer a single concept (e.g. ownership), therefore more complex ethical questions would be described as a sum of multiple ontological blocks."
    },
    {
      "title": "Common Structure of Ontological Blocks of Meaning",
      "content": "A major challenge in ethical AI is ensuring ontological blocks follow a common structure to support uniform testing and consistent term relationships. The proposed structure is simple: a primary concept paired with a binary ethical qualifier (e.g., good or bad).\nFor example, in the block \"stealing is bad\", stealing is defined as the unauthorized transfer of ownership outside quantifiable pathways like trade, gift, bequest, or taxation. This format supports clear, consistent, and transparent ethical evaluations. Block variables are selected by designers-researchers, practitioners, or stakeholders-ensuring both expert insight and public auditability. For complex concepts (e.g., medical emergency), multiple simpler blocks can be combined. This modular structure supports consistency and scalability across domains.\nThese are the foundational principles that could guide visualizing ethical AI ontological block. They include:\nFairness: Prevents bias and ensures equitable treatment. Accountability: Assigns responsibility for AI outcomes. Transparency: Promotes understandable, open AI processes AI Application Areas: Domains where ethical principles are applied. Ethical Frameworks: Structured sets of principles guiding ethical AI development.\nTogether, these components provide a robust structure for designing ethical AI systems that are principled, transparent, and aligned with current standards.\nPros and Cons of the Proposed Framework 1) Advantages: Independence from training data, enabling robust ethical evaluations. Flexibility to combine blocks across fields, such as medicine or law. Auditability of standardized blocks, improving transparency and accountability.\nDrawbacks: Labor-intensive creation of noncontradictory, quantifiable blocks. Reliance on large language models (LLMs) or external tools to infer missing relationships, introducing potential biases. Additional processing power required for integration and maintenance.\nDespite challenges, the framework's flexibility, independence, and auditability make it a promising foundation for building ethically aligned AI systems.\nA Use-Case: AI-Powered CRM and Ontological Profiling for Investor Protection Overview: Brokerage firms are increasingly using AIpowered voice assistants to enhance investor classification and risk profiling. Moving beyond static binary systems, these tools enable more precise, ethical, and adaptive assessments of investor risk tolerance, protecting retail clients from unsuitable high-risk products .\nThe Challenge: Regulations require firms to distinguish between professional and retail investors to prevent the latter from accessing high-risk instruments like synthetic options. However, current assessments often overlook real-world risk tolerance, especially under stress, leading to potential harm and regulatory noncompliance.\nThe Innovation: This use case introduces ontological blocks of meaning for product classification. A financial product might trigger a \"Riskier\" block based on:\n-Financial risk -Potential economic loss.\n-Psychological risk -Emotional reaction to financial stress. This enables real-time, context-aware, and ethically grounded risk assessment.\nHow It Works: AI voice assistants engage clients with adaptive questions (e.g., \"How did you react to your last investment loss?\"). A response like \"Not well\" may indicate emotional sensitivity. Using NLP and probabilistic modeling, the system estimates a behavioral risk profile.\nIf there's a high probability (e.g., 60%) of emotional vulnerability, a corresponding ontological block is triggered, ethically restricting access to high-risk products. This creates a personalized, behavior-informed investor classification framework."
    },
    {
      "title": "Discussion",
      "content": "The evaluation shows that combining ontological blocks with FAIR principles offers a strong foundation for ethical AI monitoring. Key insights include:\n• The unified monitoring system effectively identifies ethical risks and supports compliance (e.g., EU AI Act).\n• Ontological blocks provide structured, modular, and interpretable ethical encoding. • FAIR principles enhance discoverability, usability, and scalability. Remaining challenges include the manual effort required to build blocks and the reliance on probabilistic reasoning with incomplete data. Future work should focus on automating block creation and improving data integration."
    },
    {
      "title": "CONCLUSION AND RECOMMENDATION",
      "content": "This framework introduces ontological blocks as standardized, expert-designed tools for ethical AI assessment. These modular units enable transparent evaluations across diverse ethical contexts.\nKey strengths include independence from training data and flexibility across domains. However, challenges remain in automating block creation and managing dependencies on probabilistic models.\nBy integrating with FAIR principles, the framework supports ethical, transparent, and accountable AI systems-laying the groundwork for responsible AI development across sectors."
    }
  ]
}