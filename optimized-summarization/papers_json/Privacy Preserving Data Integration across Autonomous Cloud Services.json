{
    "title": "Privacy Preserving Data Integration Across Autonomous Cloud Services",
    "authors": "Abdul Samer;  Ghafour; Parisa Ghodous; Christine Bonnet",
    "pub_date": "",
    "abstract": "In this paper, we tackle privacy issues of data sharing services in a cloud environment. We propose a serviceoriented privacy-preserving model for data integration across autonomous clouds. Our model allows to execute aggregations of cloud data sharing services without revealing any extra information to any of the involved services. Thus, involved services enforce locally their privacy policies by applying their own access control models and data anonymization algorithms. We illustrate lack of data protection in current data sources through examples of querying data in a healthcare system.",
    "sections": [
        {
            "heading": "I. INTRODUCTION",
            "text": "Data integration across autonomous data sources has been a long-standing challenge for the database community [6], [5], [4]. This is motivated by the number of contexts in which the need for a flexible data integration mechanism is critical, including Web and enterprise data integration, integrating data pieces from smart objects in IoT-based smart environments, data sharing for scientific research, data exchange in government agencies, etc.\nIn practice, however, the development of data integration systems is often hindered by the lack of robust and flexible techniques to protect the privacy of the shared data. Existing data integration solutions are usually implemented as centralized data warehouses collecting and storing data from various data sources. Typically, data sources and data warehouses expect to sign business agreements in which the scope of the shared data and corresponding privacy policies are specified. For example, all shared data will be kept confidential and will not be disclosed to other unrelated third parties or be used for other purposes. While this solution works well for a single organization or a federation of organizations, where trust relations have been well established, serious problems will arise when some data warehouses cannot be trusted by data sources. In such cases, data sources will refuse to share their data because they have no control of its usages and disclosures once the data is shared. In fact, data warehouses indeed can reveal or abuse the shared data. Furthermore, even if data warehouses adhere to the agreement, there is no guarantee that they have sufficient capability to protect the data.\nIn this paper, we propose a service-oriented privacypreserving model for data integration across autonomous ",
            "publication_ref": [
                "b5",
                "b4",
                "b3"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A. Running Example",
            "text": "Let us consider a healthcare information system which collaborates with multiple healthcare organizations including medical research institutes, hospitals, pharmacies, pharmaceutical labs, that may manage their data through autonomous clouds. For the sake of simplicity, we assume that the system has access to the data sharing services in Table-1. Assume also that a pharmaceutical researcher, Alice, wants to investigate the correlation between a chemical component ABC present in HIV medicines and the development of severe psychiatric disorders at HIV female patients.\nObviously, Alice can answer her research questions by composing these services as follows (cf. Fig. 1). She invokes S 1 with the desired city to get the identifiers of HIV patients. Then for each obtained ssn, she verifies whether the patient has psychiatric disorders by invoking S 2 ; then for each of these patients she retrieves the age and sex by invoking S 3 and the HIV medications by invoking S 4 . For each of the obtained HIV medications, she retrieves its ABC content by invoking S 5 . Then she joins the outputs of S 3 and S 5 to link the medical and the personal information to the same patient.\nThis example showcases an interesting challenge. If the data returned by individual services were completely privacy-sanitized (by removing identifiers, e.g., ssn, and  The data accessed by S  anonymizing sensible information) then the query plan could not be executed, and the research query of Alice could not be answered. On the other hand, if returned data were not protected, then participant services, the entity executing the query and the query issuer (i.e. Alice) will learn sensitive information that they normally must not know. For instance, if the provider of S 2 has an access to the query plan, and knows that its input tuples are coming form S 1 , and assuming that the data accessed by our services are given in Fig. 2, then he will learn who of his patients have been tested positive for HIV (i.e, P 15 , P 201 and P 512 ). Similarly, the providers of S 3 and S 4 will learn who of their patients are receiving treatments for psychiatric disorders and are HIV patients. Alice and the entity responsible of executing the query will learn sensitive information about patients including their ssn, ages, medications, etc. Based on that observation, the goal of this paper is to enable the services involved in answering a query (such as the one formulated by Alice) to enforce locally their privacy policies (by applying their own access control models and data anonymization algorithms) while at the same time keeping it possible to link data subjects 1 (e.g., patients) across the different services. In this paper, we propose a privacy-preserving query execution model to execute multi-source queries over autonomous data sharing services (managed by different clouds). Our model ensures that (i) no extra information is revealed to any of the involved services, i.e., none of involved services is able to learn/infer any information about the data the other 1 We use the term data subject to mean the individual whose private information is stored and managed by data services services provide beyond what these services already know, and (ii) the entity that executes the query and aggregates intermediate results has only the necessary information to interconnect data subjects.\nP0 P8 P15 P20 P23 P188 P201 P204 P209 P411 P512 P513 P514 [0-20] sex m m null f f m null m m m f f f [0-10] [0-10] [0-20] [0-20] [0-20]",
            "publication_ref": [],
            "figure_ref": [
                "fig_1"
            ],
            "table_ref": []
        },
        {
            "heading": "II. A PRIVACY-PRESERVING COMPOSITION EXECUTION MODEL FOR HONEST-BUT-CURIOUS DATA SHARING SERVICES",
            "text": "",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A. Context and Assumptions",
            "text": "We consider a honest-but-curious environment. An honest-but-curious environment (a.k.a. semi-honest environment [2]) is one where the parties involved in the query processing (i.e., composed data services and the composition execution engine) follow correctly the given protocol, but may keep any result or information they obtain during the course of the protocol. We assume that the services, the composition execution engine and the recipient of the final results are three independent entities.\nWe consider that the attributes of a dataset can be divided into: identifier attributes and non-identifier attributes. The integration of the data subjects across the different data services is carried out using the identifier attributes. We assume the existence of universal identifiers in each application domain (e.g., the social security number in the healthcare domain).",
            "publication_ref": [
                "b1"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "B. Preliminaries",
            "text": "A Composition of Data Services H: A composition of n data services is represented as a directed acyclic graph (DAG) H in which there is a node corresponding to each data service, and there is a directed edge e ij from S i to S j if there is a precedence constraint S i \u227a S j (i.e., S j is preceded by S i when one of its inputs is an output of S i ), and where each service S i 1\u2264 i\u2264 n has a set of inputs and outputs that could be privacy-sensitive or identifier attributes. Edges e ij may be associated with constraints to filter relayed tuples. Service Selectivity Se(S i , R j ): Given a data service S i , and a range of input values R j , the selectivity of S i relative to R j is the number of outputted tuples when S i is invoked with R j . For example, assuming that the ssn values in Fig. 2 are ordered, then Se(S 3 , [P 0 , P 10 ]) = 2, Se(S 3 , [P 5 , P 20 ]) = 3, and Se(S 3 , [P 0 , P 1000 ]) = 13 are the selectivities of S 3 relative to the ranges [P 0 , P 10 ], [P 5 , P 20 ] and [P 0 , P 1000 ]. We assume that data services can provide operations (i.e., functions) to provide statistical information about their managed data (including the selectivity of a service.). Order Preserving Encryption Scheme OPES. An OPES [1] allows to encrypt numeric data values while preserving the order relation between them. This allows to apply equality and range queries as well as the MAX, MIN and COUNT queries on encrypted data, without decrypting the operands.",
            "publication_ref": [
                "b0"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "C. Privacy-preserving Composition -Execution Model",
            "text": "Our model relies on two key ideas. First, we use a combination of OPES for identifier attributes and anonymization techniques for non-identifier attributes. Composed services could apply the desired anonymization algorithms on nonidentifier attributes, but they must all use the same OPES for identifier attributes. This way the composition execution engine has only access to anonymized data and can link the anonymized information of the same data subject across the different services using the encrypted identifier attributes (recall that the OPES allows for applying equality queries on encrypted data). It cannot decrypt the encrypted identifier attribute values, as it does not have the encryption key. By the end of the composition's execution, it removes from the final results the encrypted identifier attributes before returning them to the recipient, who will thus get only the anonymized data.\nSecond, our model implements the K-protection notion that we introduce below, and which limits the knowledge leaked to participant services during the execution of H. K-protection: Given a vector K = (k 1 , k 2 , ..., k n ), where k i is an integer representing the protection degree the service S i must provide for its outputted tuples. For each edge e ij in H, the knowledge leaked to S j during the execution of H (denoted by (S j )) must be \u2264 min(1/k l ), where k l is associated with S l , which denotes the (direct or indirect) parents of S j in H. Note that S j has at least one parent in H, which is S i .\nThe above definition can be interpreted as follows: when a service S j is invoked, it must not be able to determine precisely its input value between k input values for which it has outputs; i.e., it must not be able to determine precisely the tuple t in which the invoker is interested between k tuples of its own data. This can be realized by invoking S j by a range of values R instead of a precise value v, where Se(S j , R) = K. Example: Examples of privacy breaches that could happen if the composition in Fig. 1 was executed without ensuring the k-protection requirement include: S 2 will know that its patients P 15 , P 201 and P 512 have HIV virus; S 3 will know that these same patients have HIV and suffer from severe psychiatric disorders, etc. Now, assume that K 1 = 3, the k-protection requirement implies that S 2 must not be able to distinguish each of its input values (e.g., P 15 ) from at least 3 values for which it has answers. Fig. 3 shows how the k-protection is enforced on the edge e 12 . The value P 15 is k-generalized into a range of values V which has at least three values (e.g., P 11 , P 15 and P 16 ) for which S 2 has corresponding tuples. After the invocation of S 2 , the extraneous tuples are filtered out.\nThe Model Description: As illustrated in Fig. 4, the system is composed of two main modules: the Service Composition Module which generates the composition execution plan and the Composition Execution Module which executes the composition in a privacy-preserving manner. The recipient specifies an encryption key, submits it directly to participant services in H, and launches the execution of H. When participant services are invoked, they anonymize their sensitive data and encrypt the identifiers with the supplied key. The composition execution engine implements (in the Value K-Generalization module) an algorithm to ensure the k-protection requirement when it invokes participant services. Specifically, for each invoked service S i , it determines the protection factor k that must be ensured: k = MAX(S j .k j ), where S j denotes the parents of S i in H. Then, for each input tuple t, the algorithm determines the minimum range of value R [a, b] that should be used to invoke S i instead of t. For this purpose the execution engine requests the selectivity of S i with respect to a wide range of identifier values R (we use the range ]-\u221e, +\u221e[ to denote the range covering the whole tuples set managed by S i ) along with a value v occurring in the middle of the ordered value sets held by S i . Then if the returned selectivity is greater than k, the execution engine compares the identifier attribute (denoted by x) of t to v to determine the half of R covering t, which becomes the new range R. This step is repeated with the new R until there is no R with a selectivity greater than k. Then, S i is invoked2 with the obtained range, and the execution engine retains only the output related to t.\nExample: Fig. 5 shows how the k-protection requirement is enforced on the edge e 23 . Assume that S 1 and S 2 require a protection factor k = 3. The invocation of S 2 returns the tuples corresponding to c 15 , c 201 and c 512 (i.e., the   The new range is R= ]-\u221e, c 16 ] and its selectivity is 4. The algorithm stops here as if the new range was divided then Se will be less than k.",
            "publication_ref": [],
            "figure_ref": [
                "fig_1",
                "fig_2",
                "fig_5"
            ],
            "table_ref": []
        },
        {
            "heading": "Service Aggregation System",
            "text": ".x \u2264 c 199 t.x \u2265 c 199 t.x \u2264 c 16 t.x \u2265 c 16 R = ]-\u221e,+\u221e[, Se =13; Middle value v = c 199 R = ]-\u221e, c 199 ], Se =7; Middle value v = c 16 R = ]-\u221e, c 16 ], Se =4,",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "III. IMPLEMENTATION AND PRELIMINARY EVALUATION",
            "text": "We implemented the system in Java and evaluated its performance based on a set of 40 medical data sharing services that we built in our previous work [3]. These services access synthetic medical information of more than 30.000 patients.\nWe conducted a preliminary evaluation of our techniques using the query in the running example. The query was executed 1000 times with and without privacy preservation. Evaluation showed that the execution average time with privacy is at most three orders of magnitude of time without privacy (with K i set to 4). Furthermore,we were able to reduce time to two orders of magnitude by reusing the selectivities and the ranges computed in past invocations of the same services.\nIV. CONCLUSION This paper addresses privacy issues with aggregated services in a cloud environment. We have considered an example in the healthcare system to illustrate privacy issues when participants may access to sensitive information that they normally must not know. Our proposed solution enforces privacy policies for services involved in answering a query by applying their own access control models and data anonymization algorithms. We are currently working on extending our model to make it multi-dimensional, i.e., when the identifier of a data subject includes the combination of multiple attributes.",
            "publication_ref": [
                "b2"
            ],
            "figure_ref": [],
            "table_ref": []
        }
    ],
    "references": [
        {
            "ref_id": "b0",
            "title": "Orderpreserving encryption for numeric data",
            "journal": "",
            "year": "2004",
            "authors": "R Agrawal; J Kiernan; R Srikant; Y Xu"
        },
        {
            "ref_id": "b1",
            "title": "Privacy preserving query processing using third parties",
            "journal": "",
            "year": "2006",
            "authors": "F Emekc \u00b8i; D Agrawal; A E Abbadi; A Gulbeden"
        },
        {
            "ref_id": "b2",
            "title": "On-demand data integration on the cloud",
            "journal": "",
            "year": "2014-07-02",
            "authors": "S A Ghafour; P Ghodous"
        },
        {
            "ref_id": "b3",
            "title": "Efficient privacy-aware record integration",
            "journal": "",
            "year": "2013",
            "authors": "M Kuzu; M Kantarcioglu; A Inan; E Bertino; E Durham; B Malin"
        },
        {
            "ref_id": "b4",
            "title": "Advanced Research in Data Privacy",
            "journal": "Springer",
            "year": "2015",
            "authors": "G Navarro-Arribas; V Torra"
        },
        {
            "ref_id": "b5",
            "title": "Securing database as a service: Issues and compromises",
            "journal": "IEEE Security & Privacy",
            "year": "2011",
            "authors": "J Weis; J Alves-Foss"
        }
    ],
    "figures": [
        {
            "figure_label": "1",
            "figure_type": "figure",
            "figure_id": "fig_1",
            "figure_caption": "Figure 1 .1Figure 1. The Composition Plan",
            "figure_data": ""
        },
        {
            "figure_label": "3",
            "figure_type": "figure",
            "figure_id": "fig_2",
            "figure_caption": "Figure 3 .3Figure 3. Ensuring the k-protection on the edge e 12 (k=3)",
            "figure_data": ""
        },
        {
            "figure_label": "",
            "figure_type": "figure",
            "figure_id": "fig_3",
            "figure_caption": "Figure 4. Implementation",
            "figure_data": ""
        },
        {
            "figure_label": "",
            "figure_type": "figure",
            "figure_id": "fig_4",
            "figure_caption": "t",
            "figure_data": ""
        },
        {
            "figure_label": "5",
            "figure_type": "figure",
            "figure_id": "fig_5",
            "figure_caption": "Figure 5 .5Figure 5. Finding the minimum range for invoking S 3",
            "figure_data": ""
        },
        {
            "figure_label": "",
            "figure_type": "table",
            "figure_id": "tab_2",
            "figure_caption": "1 The data accessed by S 2The data accessed by S 3The data accessed by S 4The data accessed by S 5",
            "figure_data": "l1l2t1l3t2t3Figure 2. Sample of the data accessed by the data servicesBegincityS 1ssnS 2ss n ss nS 3 S 4S 5 ssn, age, sex ssn, med ssn , me d, quJoinEndComposition Plan"
        }
    ],
    "formulas": [
        {
            "formula_id": "formula_0",
            "formula_text": "P0 P8 P15 P20 P23 P188 P201 P204 P209 P411 P512 P513 P514 [0-20] sex m m null f f m null m m m f f f [0-10] [0-10] [0-20] [0-20] [0-20]",
            "formula_coordinates": [
                2.0,
                251.28,
                86.67,
                74.53,
                127.51
            ]
        },
        {
            "formula_id": "formula_1",
            "formula_text": ".x \u2264 c 199 t.x \u2265 c 199 t.x \u2264 c 16 t.x \u2265 c 16 R = ]-\u221e,+\u221e[, Se =13; Middle value v = c 199 R = ]-\u221e, c 199 ], Se =7; Middle value v = c 16 R = ]-\u221e, c 16 ], Se =4,",
            "formula_coordinates": [
                4.0,
                88.92,
                255.43,
                176.77,
                100.81
            ]
        }
    ],
    "doi": "10.1109/CLOUD.2015.160"
}