{
    "title": "Are Science, Technology, and Engineering Now the Most Important Subjects for Ethics? Our need to respond",
    "authors": "Brian Patrick Green",
    "pub_date": "",
    "abstract": "In this paper I argue that, yes, science, technology, and engineering are now the most important subjects for ethics to study. Due to the dramatic expansion of human power brought about by science, technology, and engineering, ethics needs to reevaluate how humans should act given our new power. But it is not only ethics that needs to study science, technology and engineering -likewise, scientists, technologists, and engineers need to study ethics with great diligence, and embody ethical behavior in their lives, as befits many professional engineering societies' goals of holding paramount the \"health, safety, and welfare\" of the public.",
    "sections": [
        {
            "heading": "INTRODUCTION",
            "text": "Throughout the ages many philosophers have argued that happiness is the highest human good [1,2,3,4]. Not the happiness of fleeting pleasures, but rather the much more comprehensive happiness of a flourishing life, one fulfilled through excellence in virtue; the happiness of a life well-lived. Virtues are excellences of the human character, like courage, skill, and wisdom. The moral virtues are acquired by habituation, and the individual components that drive this habituation are the particular actions of moral agents. Actions, in turn, are made possible by power -we can only do what is within our ability to do. And human power, in turn, is enabled by knowledge (facts, methods, skills, etc.), tools (broadly defined), and social organization. Science, technology, and engineering (STE) have dramatically increased both our knowledge and the tools at our disposal. Natural science unlocks knowledge, and technologists and engineers use that knowledge to create new things that give us new abilities -abilities to perform old tasks with greater efficacy as well as to perform entirely new tasks. We have also, thanks to communication and transportation technologies, greatly enlarged our social organizations. Therefore, both directly and indirectly, STE have massively enhanced human power. One only needs to think of climate change to see that humanity has become capable of producing actions with planetary-scale consequences. This enormous power has implications for ethics.\nThe purpose of this paper is to show, first, that STE are qualitatively changing the nature and scope of human action and power, and that this is relevant for ethics. Second, that these qualitative changes in the nature and scope of human action and power now make STE the most important subjects for ethical investigation. Third, that there are some potential key points of intervention which can help STE and ethics become better integrated, and thus help us to better control how these tremendous new powers are applied, to ensure they are used to assist human flourishing and not to hinder it.",
            "publication_ref": [
                "b0",
                "b1",
                "b2",
                "b3"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "II. THE NEW NATURE AND SCOPE OF HUMAN ACTION AND POWER",
            "text": "Human action and power are now significantly beyond what they were in past centuries. For example, we are now capable not only of communicating and traveling great distances, consuming plentiful food and entertainment, and enjoying advanced medical and reproductive technologies, but also of using nuclear weapons, destroying vast ecosystems, creating biological and computer pathogens, and changing the planetary atmosphere and sea-level. These are unprecedented powers in human history, more like those of minor gods than mere mortals, and we are reaching for still more.\nEthics is the study of human action with respect to the good, the good being human excellence and flourishing. As the nature and scope of human action and power change, so too must ethics, or we risk not only miscalculating the dangers we face, but also failing to see new opportunities to promote excellence and flourishing.",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A. What Technology Changes",
            "text": "In the 1970s, the philosopher Hans Jonas was already arguing that due to technology the nature and scope of human action had changed. Jonas argued that whereas previously human actions were limited in spatial and temporal effect, now, because of technology, our actions are (1) aggregate (the sum of all human actions worldwide), ( 2) cumulative (building up over time), (3) irreversible (as in extinctions), and (4) long term [5]. Climate change provides a prime example of these effects. Climate change is caused by the cumulative sum of the aggregate of human fossil fuel burning and other related activities. Some of the effects of climate change may be reversible, such as the gradual removal of carbon dioxide from the atmosphere, but some will not be, such as losses involving human lives and property, as well as habitat loss and extinctions. Lastly, climate change is, of course, a very long term problem, building up over several centuries and not likely to be resolved in less than a similar amount of time. Altogether this leads to a situation with decreased ability to predict outcomes and increased risks of negative outcomes, and therefore greatly increased caution is advisable.\nGoing beyond Jonas, we might add that new technology also can be (5) non-linear in its effects (involving complex positive and negative feedback loops), ( 6) sometimes democratizing and decentralizing of power (empowering individuals for good and for ill, as with automobiles, firearms, computer programming, the internet, smartphones, and soon 3D printing and do-it-yourself (DIY) biotechnology), (7) sometimes very centralizing of power (e.g., technology leads to new monopolies or near-monopolies, such as Bell Telephone, Standard Oil, Microsoft, Google, etc., or giving power to the already powerful, e.g. contemporary spying schemes), and (8) dependency-generating (as anyone who has lost their running water, electricity, internet, smartphone, etc., can attest). Not all technologies will generate all effects, and the list is not meant to be exhaustive, but there are overall trends.\nThese factors combine to create a qualitatively different type of power than what humans have had in the past. Past ethical systems dealt with relatively simple human to human interactions, or human to society interactions, but now our individual actions cannot be accepted as merely individual actions. Our actions, thanks to technology, can be much larger in scope (e.g., our energy consumption habits endangering global climate), and completely different in nature (e.g. control of atmospheric composition was never a concern of previous ethics).\nGiven these changes in the nature and scope of human action and power, it is worth asking how ethics, which studies the proper way to control action and power, ought also to change, so as to best direct these new powers towards the good.",
            "publication_ref": [
                "b4",
                "b6"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "B. An Ethics for Technological Power",
            "text": "From intentional and positive advances such as medical and electronic technologies, to unintentional and negative sideeffects of technology such as pollution and climate change, to intentional and dangerous technologies such as nuclear and biological weapons, STE have given contemporary humans a whole host of powers that previous generations could only dream of. With god-like power comes the need for god-like moral judgment and self-control, or else -as we already know -we become dangers to ourselves (weapons, pollution, etc.) and others (habitat loss, extinctions, etc.).\nBecause STE increase human power, because increased power broadens the scope of human action and what goods we can and cannot attain, and because ethics is the study of human action with respect to the ultimate good of human happiness and flourishing, the empowering fields of STE should become the focus of more ethical attention because they are directly relevant to human excellence, not only in how they affect humans as subjects of technological power, but also for how they shape us as agents who wield technological power.\nIn light of these concerns, what changes might be warranted to human ethics? Jonas considered this as well. Humanity must broaden its ethical concern as it has broadened its power. Ethics needs to become (1) more concerned with larger-scale activities which affect not only humans but also nature, (2) prepared to face deep uncertainties in the effects of its actions and therefore concomitantly cautious in its actions, (3) given uncertainty, more concerned with obtaining knowledge of potential outcomes, and (4) concerned for the existence of and possible extinction of humanity as a whole. These concerns lead Jonas to formulate his \"imperative of responsibility\" which states \"'Act so that the effects of your action are compatible with the permanence of genuinely human life'; or expressed negatively: 'Act so that the effects of your action are not destructive of the future possibility of such life'\" [5].\nSuch an imperative to protect the very existence of humanity may seem alarmist, but there is no reason to deny the validity of the fear. In fact, despite the decline of the Cold War, investigating the question of human extinction has become something of a growth industry in the last few decades, as we have moved from the terror of nuclear war to the threat of climate change and other more futuristic threats. Philosopher Nick Bostrom has even made a scale to categorize these risks, with the largest ones being \"global catastrophic risk\" (risks which threaten massive global disaster) and \"existential risk\" (risks which threaten human extinction) [6]. Certainly some of these risks are easily comprehensible, and actions have been taken by numerous governments and other organizations to begin to minimize some threats. For example, the Montreal Protocol on Substances that Deplete the Ozone Layer has successfully reduced the risks of chlorofluorocarbons and similar chemicals which damage the Earth's protective ultraviolet-blocking ozone layer, and a series of climate-related treaties have attempted to similarly restrict carbon dioxide emissions, though to less avail.\nSo while the need is real, and some activities have begun to address these needs, what more needs to be done? Here taking the broad perspective, as Jonas does, may help to get past the limitations in our current efforts to solve global problems. However, while his imperative of responsibility is a greater ethic for species with greater power, it is abstract and hard to relate to particular situations. Therefore we must do some work in order to bridge this conceptual space between abstract and concrete in new ways. Who should be the ones to do this work?\nTo put it as clearly as possible, the ones to do this work should be the STE professionals themselves. Because technology is the cause of the enhanced human power which is necessitating the transformation of ethics, those people who are involved with the generation of this technology have a special responsibility to create that technology in such a way that it can be controlled and used for good, and not for ill. As many engineering codes of ethics note (IEEE, NSPE, ASCE, ASME, etc.) engineers are charged with protecting the \"health, safety, and welfare\" of the public. Therefore, if engineers are now producing products that are endangering the existence of all humankind, engineers are now tasked with protecting the existence of humankind itself. While engineering has stated this responsibility most clearly, this responsibility should be shared with all the STE professions, not just engineering. This is a tall order, much beyond what most would task STE with as disciplines, and one towards which Carl Mitcham has stated that engineering (not to mention science and technology in general) is not now particularly well-suited [7]. But I think the logic is clear. If you create the danger, you are responsible for controlling it. Furthermore, it means STE professionals must be increasingly involved with politics, since it is at the political level that the largest-scale decisions must be made which involve the common good. This, of course, has already been occurring, as experts are regularly brought in to testify before congress and lobby lawmakers. But is this enough? I do not believe it is, as I will argue in the next two sections.",
            "publication_ref": [
                "b2",
                "b4",
                "b5",
                "b6"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "III. WHY SCIENCE, TECHNOLOGY, AND ENGINEERING SHOULD NOW BE THE TOP PRIORITY FOR ETHICS",
            "text": "The qualitative differences in human power, which cause a need for a qualitative change in the conduct of human moral behavior, make STE now the most important subjects for ethics, for several reasons. First, most basically, more power entails more ethical responsibility. Second, while other areas of ethics are well-developed, STE ethics is not. Third, technological power is the chokepoint for the application of power through other disciplines. Fourth, other disciplines have not and cannot constrain STE because they lack the authority, competence, and/or desire; therefore STE needs to consider constraining itself .",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A. More Power Entails More Responsibility",
            "text": "We are morally responsible for that which is in our power to control, and we are not morally responsible for that over which we have no power. For example, historically, humans have not been responsible for the eruptions of volcanoes, we have not been responsible for earthquakes, we have not been responsible for asteroid strikes, for environmental radioactivity, for the Earth's atmospheric composition, climate, storms, hurricanes, or sea level. And yet now, for all of these, we are already, to varying degrees, responsible. Human activity most likely triggered a massive mud-volcano in Indonesia. Human activities such as geothermal power production and fracking can cause earthquakes. Human activity has significantly increased environmental radioactivity in certain locations, whether through the use of nuclear weapons or via accidents. We now have the power to detect and perhaps respond to potentially dangerous asteroids (whether by evacuation or other means). We have changed the Earth's atmospheric composition by altering the levels of carbon dioxide, chlorofluorocarbons, methane, and other gases, thus changing climate, causing more powerful storms and hurricanes, and raising sea level. In addition, there also are or will be such human-generated risks as those presented (whether intentionally or accidentally) by nanotechnology, human-generated pandemics, artificial intelligence, autonomous military robots, geoengineering, and so on.\nWhat level of responsibility are we talking about? Once again, we face the questions of global catastrophic and existential risks. These threats can be helpfully analyzed using the risk equation: risk = harm x probability. If for any risk the harm is unacceptable (effectively making it negative infinity) and the probability is non-zero, then the risk is too high [8,9]. We should consider global catastrophic and existential harms as being too high; therefore we should try to reduce their probabilities of occurring towards zero, if we can make decisions which lead towards that end.\nOur responsibility has grown to include these risks and yet we seem not fully to recognize this new responsibility, nor be able to assign this responsibility to social organizations capable of meeting it. We need to recognize these changes, acknowledge our new responsibility, and begin to think about how to control these powers, or else we will possess these powers in a semi-controlled or an uncontrolled manner, as wequite apparently -do now.",
            "publication_ref": [
                "b7",
                "b8"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "B. The Field of Science, Technology, and Engineering Ethics is Relatively Underdeveloped",
            "text": "Second, while other areas of ethics such as medical, business, environmental, and legal ethics are well-developed, STE ethics is not. STE ethics needs to have as strong an academic and professional presence as medical ethics and business ethics, if not (considering the marginal success of those disciplines and the higher stakes in STE) much more.\nHow exactly can one determine if a discipline is \"relatively underdeveloped\"? There are many possible ways to approach the problem. One could go by the total number of scholars in a field, by the total number of students, the number of courses taught, by the frequency of conferences, by the number of publications, by how publicly well-known a field is, by its prestige, influence, efficacy, quality, and so on. On all of these counts I have an intuition that engineering ethics (as an exemplar of STE ethics) is underdeveloped; this IEEE symposium on ethics, as the first of its kind, is a prime example. But it would be good to have at least some hard data.\nAs a quick approximation of relative development of several fields of ethics, I used Google Books Ngram viewer (which searches word frequencies in the books Google has digitized) and Google Scholar (which searches scholarly publications) to compare the terms \"medical ethics,\" \"business ethics,\" \"environmental ethics,\" \"legal ethics,\" and \"engineering ethics.\"\nIn the Google Ngram database, the results as percentages of the database (case insensitive) for the year 2000 are as follows:\n\"Medical ethics\" = 0.0000889114% \"Business ethics\" = 0.0000755499% \"Environmental ethics\" = 0.0000536808% \"Legal ethics\" = 0.0000186233% \"Engineering ethics\" = 0.0000059436%\nOther terms such as \"science ethics,\" \"ethics in science,\" \"technology ethics,\" and \"ethics of technology\" were even lower than \"engineering ethics.\" This information is out of date and the data set is incomplete, so it serves only as a first approximation [10,11].\nHowever, Google Scholar gives a similarly ranked outcome to the above, with the search term \"medical ethics\" producing 507,000 results, \"business ethics\" 330,000 results, \"environmental ethics\" 60,000 results, \"legal ethics\" 37,500 results, and \"engineering ethics\" just 16,500 results. [12] There could, of course, be other problems here, like usage of terms (ethics or morals? science or engineering or technology? \"Medical ethics\" or \"ethics in medicine\"?), but the overall results are fairly clear. This helps validate the common-sense intuition that the discipline of engineering ethics in particular and STE ethics in general is underdeveloped relative to other disciplines of ethics, and therefore, combined with the importance of the endeavor, in need of significantly more attention.",
            "publication_ref": [
                "b9",
                "b10",
                "b11"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "C. Science, Technology, and Engineering Are the Chokepoints for the Application of Power in Other Fields",
            "text": "Third, technological power is the chokepoint for the application of power through other disciplines. For example, contemporary government surveillance relies on computers and computer programmers. The professionals who work on these projects have recently become acutely aware of this fact, and, in addition to the acts of disobedience of Bradley/Chelsea Manning and Edward Snowden, at least one engineer, Bruce Schneier, has issued a call to constrict this chokepoint [13].\nContinuing with the first four of the five ethics disciplines noted above, we can see that all involve STE to a very great degree; in fact, STE are often the root of many of the ethical dilemmas in those disciplines. For example, when medical ethicists face a difficult new challenge it is often because medical technology has produced a new situation, e.g. \"brain death,\" in vitro fertilization, organ transplantation, etc. STE are certainly crucial to business as well, with technology presenting huge opportunities and challenges, both with ethical repercussions. Environmental ethics exists as a discipline because STE have enabled humans to endanger the environment, which is a power past humans never did wield. Lastly, STE present challenges to law and can call legal ethics into play, as debates proceed over the legal status of all sorts of new technologies such as self-driving cars, do-it-yourself biotechnology, embryonic stem cell research, etc.\nTechnology is the commonality between ethical problems across fields, yet without taking the long view we could almost miss it. Similarly, STE professionals present a commonality across these fields, and yet due to a lack of strong professional identity might not realize that they have this commonality and power. Too often, STE professionals are treated as parts in a machine, where business managers make decisions and scientists, technologists, and engineers obediently carry them out, perhaps without deeply considering the contexts and largescale effects of their actions (and as Mitcham notes, there may be, at least for engineering, historical reasons for this related to its military origins [7]). But these contexts and large-scale effects must be considered, and STE professionals are exactly the right people to be considering them because they are the experts on the technology. Or rather, they are the right people if they are trained to perceive these problems and how to approach them. When well-trained STE professionals see a technologically induced moral vulnerability ahead, they should do their best to mitigate the vulnerability, e.g., building privacy protection into computer programs at the start, not as an afterthought. Concomitantly, and to avoid dwelling only on the bad, technologically induced moral opportunities -new ways to help people -should be perceived and pursued also.\nThe weakness here is that STE professionals are often embedded in organizations that disperse decision-making, downplay their authority, and/or put profit above ethics. But if STE professionals simply asserted the power that they already have, the balance of power in decision-making could shift strongly towards them. However, this requires the construction of a much stronger professional identity. This is, therefore, something that requires serious thought and action.",
            "publication_ref": [
                "b12",
                "b6"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "D. Other Disciplines Have Not and Cannot Constrain",
            "text": "Science, Technology, and Engineering Fourth, while other disciplines could try to constrain STE, they do not, because they lack the authority, the competence, or the desire (because they benefit from STE). Thus, STE need to consider constraining themselves -not to prevent innovation, but to safely manage it, especially with dual-use research and technologies.\nDue to past abuses, the field of medicine does act to prevent certain kinds of research, for example banning research without informed consent. Business ethics has made some abuses illegal, such as insider trading, and some technologyrelated problems have been constrained, such as those presented by computerized stock trading. Environmental ethics has likewise turned to the law to prevent egregious abuses such as the dumping of toxic waste. And so on. Furthermore, US government agencies exist to enforce these regulations, for example the National Institutes of Health, the Securities and Exchange Commission, and Environmental Protection Agency But while all these disciplines have reacted to ethical problems presented by or associated with particular relevant technologies, none of them have become or can become proactive in order to address the problem at its source. The source of the problem is the development of technology in general, and this domain itself lies beyond the disciplinary competency and authority of any of these individual disciplines. It is, or rather ought to be, a discipline in its own right, one which studies the commonalities of problems generated by technology across a broad spectrum of fields. This is a much harder task, bringing forth conclusions from it will be difficult, and producing a generic technology regulatory body may nigh be impossible. But this is the situation we face. Unconstrained technological development may threaten the very existence of humanity. At the risk of this infinite loss, we should do everything we can to mitigate the risk.\nTogether, these four above issues indicate how very seriously moral philosophers and ethicists ought to take science, technology, and engineering. These disciplines are in desperate need of further thought and action. But should this attention be a one-way street, where it is solely the obligation of those interested in morality to learn about STE, or should there be something more? If STE should be a top priority for ethics, then ethics also should be a top priority for STE.",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "IV. WHY ETHICS SHOULD NOW BE THE TOP PRIORITY FOR SCIENCE, TECHNOLOGY, AND ENGINEERING",
            "text": "If the goal of engineering (and STE more broadly) is \"to promote the health, safety, and welfare of the public,\" and health, safety, and welfare are goods that enable us towards excellence and eventually a comprehensive type of happiness, then not only should ethics learn STE, but STE should learn ethics. What actions should be taken to begin to strengthen the relationship of STE and ethics? I propose a three-pronged approach this question.",
            "publication_ref": [],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "A. The Role of Science, Technology, and Engineering Schools",
            "text": "First, ethics courses should be mandatory for all students in STE. While STE are already packed with requirements, aimless power can be extremely dangerous, and ethics can provide guidance in dangerous terrain. STE professionals in training need to know that they are embarking upon a journey where they may have the fates of many people in their hands. This is not a journey for the callous or faint-hearted. There are several excellent text-books for courses like these and many useful articles, but the practical implementation of these good ideas could still use some work.\nMy experiences teaching engineering ethics at Santa Clara University have been extremely positive, especially when ethics is understood not as a barrier to what one wants to do, nor as a purely defensive measure against lawsuits, but rather as a way to help people, to have meaningful and fulfilling work, and to protect cherished values such as a healthy environment, privacy, or justice. One of the worst things we can do is to reduce ethics to fear. On the one hand, ethics does involve fear, because mistakes do harm people. But on the other hand, ethics also involves hope and a vision for a better future, allowing us to achieve moral goods that we do not yet have. Combined with innovation by STE, that moral hope can be actualized into reality, as many developments in the field of frugal innovation have proven, e.g. solar or gravity powered LED lighting, solar-powered cell-phone chargers, affordable cooking stoves and small refrigerators, banking by cell-phone, and so on. Examples such as these can serve as positive case studies.\nOf note here is the vital role of cases in the study of STE ethics. There are certain archetypal cases, like the 1986 Space Shuttle Challenger disaster, that will be discussed for decades. This intense focus on learning via cases -casuistry -is something STE ethics shares with the medical and legal fields. Given this fact of education, it could be of some benefit to discuss how casuistry works as an ethical method, and how it serves to teach. Albert Jonsen and Stephen Toulmin's classic text on the method The Abuse of Casuistry could be useful reading [14]. And, as noted above, not only negative case studies ought to be taught, but positive ones as well. We want to not only direct students away from the bad, but actively lead them towards the good: the health, safety, and welfare of the public.\nCasuistry as a method relies on imagination and analogy, but it also relies on its users being good people. In other words, casuistry has a long historical relationship with virtue ethics. Vicious individuals will always be able to bend casuistry in ways to make the method serve their ill will, so some training in virtue is necessary to wield the method in a reasonable way. Charles Harris, Jon Alan Schmidt, and others have recently begun to emphasize virtue ethics in engineering, and this is a very good thing [15,16]. It is additionally important to note that moral virtue is acquired by practice -by actually doing things (like technical skills are trained) -and not only by theoretical classroom discussions. Training morally good STE professionals requires practical experience and mentorship. While \"virtue is its own reward,\" it should also not be missed that this sort of training is good for leadership and general success in the STE fields because it trains perceptivity to larger scale needs of society and thus how to find opportunities, e.g., for successful business ventures.\nUnfortunately, some research has shown that despite some engineering schools' good efforts, engineering students still lose social awareness and concern over the course of their studies, no matter whether the school emphasizes these considerations or not. [17] More research is required to determine how STE professionals can be trained to be more interested in social and moral questions, and more able to deal competently with these issues.",
            "publication_ref": [
                "b13",
                "b14",
                "b15",
                "b16"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "B. The Role of Science, Technology, and Engineering Professional Organizations",
            "text": "Second, STE practitioners should become more professionalized. Perhaps most or all STE practitioners should be required to be licensed by a professional society. Yes, some STE professionals are already licensed, such as structural engineers, but computer programmers -who in some respects are now among the most powerful individuals on the planetare not, and perhaps they ought to be. Neither are biotechnologists required to be licensed, but given the advent of the age of do-it-yourself genetic engineering, perhaps they ought to be as well. Serious STE malpractice should entail loss of license, or even civil or criminal penalties, as in medicine and law; this will also require government enforcement.\nA first objection, particularly for engineers and technologists, might be that it is not STE professionals who make immoral decisions in the midst of projects, or it is not for them to decide what is right or wrong; instead these roles belong to management. This objection is wrongheaded. Management often are not knowledgeable enough to make decisions without the consent of STE professionals. If STE professionals refuse to cooperate with bad management decisions (and it must be the entire profession, or else firings and replacements with undercut the system), then morally flawed projects would not continue and immoral actions would be prevented.\nAs an analogy, imagine a hospital administrator commanding doctors to neglect, put at risk, or even directly harm patients who would otherwise cause too much expense to the hospital (and I am not saying this does not occur, perhaps especially in nursing homes or during end-of-life care). The medical professionals of the hospital should rightly refuse this callous and immoral directive. STE professionals should be able to do the same under analogous circumstances. If currently the STE professions are failing to stop bad management decisions due to a lack of cohesion in the face of a more powerful force, then professionalization might provide the necessary leverage to respond. As any labor union knows, seemingly intractable problems with management can be made soluble. In fact, unions would not be necessary, if only the professional identity of STE became such that management would never think of second guessing their decisions or of asking them to act against their professional ethical codes (as hospital management should not with doctors). Failures by STE professionals to adequately prevent mismanagement can and must be remedied as the stakes in STE become higher and higher. The \"management made me do it\" excuse (akin to the military \"I was just following orders\" excuse, which is also morally and legally unacceptable) has before and will again sully the reputation of STE unless actions are taken.\nA second objection might be that the professional borderlines of STE are unclear. This is certainly true. However, the fact of dusk does nothing to disprove the existence of day and night. STE professionals clearly do exist. STE hobbyists might not like the idea of getting in trouble for \"practicing STE without a license,\" but it completely depends on the nature of their work. An amateur astronomer is probably not much of a threat to anyone's health, while someone engaged in DIY genetic engineering might be, and someone doing home radiological experiments certainly is (as recently happened in Sweden [18]). This leads to a third objection, which is that this type of professional regulation may stifle innovation. This is an understandable objection, and given the wrong regulatory structures it could be a real problem. But there are ways to approach these issues with a light regulatory hand that would have little or no effect on innovation while also helping prevent dangerous accidents or malicious attacks. One way could be simply to have a list of who in the country has relevant or dangerous STE skills. Privacy advocates would understandably bristle at such a list, and I'm not sure it would be the best way to approach regulation, but it would be one way. Another way, as mentioned above, is a licensing approach. Another would be restriction of access to key bits of knowledge, though as nuclear proliferation has shown, secrets are hard to keep for long. Restriction of materials is another approach. As law enforcement against methamphetamine labs has shown, choosing what to restrict is crucial; often controlling one key ingredient, e.g. pseudoephedrine, can be the difference between success and failure. Overall, some approaches may work for some technologies, but not others, for example, restricting uranium and plutonium works fairly well for controlling nuclear technology, but restricting access to common lab supplies might be less effective for controlling biotechnology.\nThere are many more possibilities for professional regulation, and they should be considered carefully. Much more thinking needs to be done, and it may be difficult to put into practice, but difficulty should not be an excuse from doing it.",
            "publication_ref": [
                "b17"
            ],
            "figure_ref": [],
            "table_ref": []
        },
        {
            "heading": "C. The Role of Government Oversight, Legal Regulation, and Policy",
            "text": "Third, because the effects of STE are now on a grand scale, their governance should be on a similarly grand scale. While many governments and the UN already have some institutional structures relevant for some aspects of STE governance, these institutions should be given \"teeth.\"\nWe are already at a point in history where highly motivated people in small groups can commit terrible crimes; some examples include the 1984 Rajneeshee salmonella attack, the Aum Shinrikyo sarin gas attacks in 1994 and 1995, and the September 11th hijacking attacks in 2001. Technology has also empowered individuals to become capable of devastating attacks; both highly trained ones, such as the 2001 anthrax attacker, and untrained ones, such as various spree shooters and suicide bombers. While not all of these attacks involved STE professionals, several did, and all utilized technology that at some point was developed by STE. Could more have been done at the outset to reduce the dual-use dangers of these technologies, or better control their use and proliferation, and prevent their abuse? We need to become more creative in our thinking about how to control our technology, because the trends are clear: in the future, as technological power becomes more advanced and democratized, the cost-to-benefit ratio will grow even more unacceptable, and the risks simply too high.\nOne objection here might be that researchers who do \"pure science\" could not possibly be a threat because they work on the production of knowledge, not on creating dangerous technological artifacts. There is some truth to this objection, but even \"pure\" science often involves the generation of new technological artifacts, such as telescopes, supercomputers, particle accelerators, etc. And those large and innocuous artifacts, while of obvious use for pure science, might also be used for nefarious purposes, for example computer simulations for the design of new nuclear weapons. The recent controversy over laboratory-generated gain-of-function mutations in H5N1 avian flu, creating strains transmissible between mammals, reveals another aspect of the problem. This was \"pure science\" research, but it had a more distant applied end in the knowledge of what dangerous genetic changes we ought to look for, should H5N1 naturally mutate. Yet, in preparing for the worst-case-scenario, the researchers themselves created in the laboratory the potential for the worst-case scenario in reality, risking a massive and deadly human epidemic. This \"dual use research of concern\" (DURC) is the kind of research that needs to be heavily regulated, and restricting our concern to the applied or technological sides will not be enough. Insofar as STE professionals create new technologies, or information applicable to how others might make these technologies, they should be partnered with regulatory agencies.\nBecause we live in a democracy, public input is crucial for addressing these governance-level issues. At the same time, because STE governance is intrinsically specialized and requires expert knowledge, this is an impediment to public participation. The public should participate, but it should also be properly informed, or its participation may not serve the common good. Leon Kass, Carl Mitcham, Mike Martin and Roland Schinzinger, and others have discussed the role of the public with regards to governance, and all are valuable contributions to the discussion [19,20,21]. In particular, the notion of \"societal informed consent\" deserves some attention from STE professionals [22,23,24]. If medical doctors require informed consent in order to pursue the individual good of their patients, then STE professionals, some of whom have explicitly described their \"patient\" as the public and their goal as the public's \"health, safety, and welfare,\" need to somehow deal with this concept. While these changes in education, professionalization, and governance may sound severe, I think they only sound so because they are changes. After all, medicine and law are already practiced in this more regulated manner, and most agree that this regulation is good, not bad. As the STE professions join law and medicine in power, and exceed them, they should adopt the good practices of those fields.\nV. CONCLUSION Science, technology, and engineering provide humanity with immense power, both for good and for ill. Through these new powers, STE provide new ways to achieve a good and flourishing life and also new ways to harm and destroy that life. Ethics needs to learn to adapt to STE and the powerful new realm of action it has created, and STE professionals need to accept their new ethical responsibilities as participants in a process that is capable of re-making the world, for better or for worse.\nScientists, technologists, and engineers ought to accept their charge as the protectors of the health, safety, and welfare of humanity. Why ought they to accept? Because they are precisely the people who, through their power, have put humanity in this danger, and are therefore also the only ones who are capable of controlling that power and guarding humanity from it.\nOnce again, this may sound extreme, beyond what STE professionals \"signed up for,\" but I believe there is no other conclusion to be drawn. Accepting this charge is the only morally acceptable solution. It is also a great honor, to be placed with high responsibilities and fulfill them well. The alternative pathway to the future is rejection of this task and denial of responsibility, thereby leaving humanity with few or no knowledgeable guides or guardians as we face the perils of the future. Which path we choose is up to us.",
            "publication_ref": [
                "b18",
                "b19",
                "b20",
                "b21",
                "b22",
                "b23"
            ],
            "figure_ref": [],
            "table_ref": []
        }
    ],
    "references": [
        {
            "ref_id": "b0",
            "title": "",
            "journal": "Hackett Pub. Co",
            "year": "1999",
            "authors": "Nicomachean Aristotle;  Ethics"
        },
        {
            "ref_id": "b1",
            "title": "",
            "journal": "I-II",
            "year": "1947",
            "authors": "T Aquinas; Summa Theologiae"
        },
        {
            "ref_id": "b2",
            "title": "Natural Goodness",
            "journal": "Oxford University Press",
            "year": "2001",
            "authors": "P Foot"
        },
        {
            "ref_id": "b3",
            "title": "After Virtue, 2nd ed",
            "journal": "University of Notre Dame Press",
            "year": "1984",
            "authors": "A Macintyre"
        },
        {
            "ref_id": "b4",
            "title": "The Imperative of Responsibility",
            "journal": "University of Chicago Press",
            "year": "1984",
            "authors": "H Jonas"
        },
        {
            "ref_id": "b5",
            "title": "The concept of existential risk",
            "journal": "The Journal of Evolution and Technology",
            "year": "2002-03",
            "authors": "N Bostrom"
        },
        {
            "ref_id": "b6",
            "title": "A philosophical inadequacy of engineering",
            "journal": "The Monist",
            "year": "2010",
            "authors": "C Mitcham"
        },
        {
            "ref_id": "b7",
            "title": "Three nuclear disasters and a hurricane",
            "journal": "Journal of Applied Ethics and Philosophy",
            "year": "2012-08",
            "authors": "M Davis"
        },
        {
            "ref_id": "b8",
            "title": "Small theories and large risks-is risk analysis relevant for epistemology?",
            "journal": "Risk Analysis",
            "year": "",
            "authors": "M M Cirkovic"
        },
        {
            "ref_id": "b9",
            "title": "Quantitative analysis of culture using millions of digitized books",
            "journal": "Science",
            "year": "2011-01-14",
            "authors": "J-B Michel"
        },
        {
            "ref_id": "b10",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "Google Ngram; Viewer "
        },
        {
            "ref_id": "b11",
            "title": "",
            "journal": "",
            "year": "",
            "authors": "Google Scholar"
        },
        {
            "ref_id": "b12",
            "title": "The US government has betrayed the internet. We need to take it back: The NSA has undermined a fundamental social contract. We engineers built the internet -and now we have to fix it",
            "journal": "",
            "year": "2013-09-05",
            "authors": "B Schneier"
        },
        {
            "ref_id": "b13",
            "title": "The Abuse of Casuistry: A History of Moral Reasoning",
            "journal": "University of California Press",
            "year": "1988",
            "authors": "A R Jonsen; S Toulmin"
        },
        {
            "ref_id": "b14",
            "title": "The good engineer: giving virtue its due in engineering ethics",
            "journal": "Science and Engineering Ethics",
            "year": "2008",
            "authors": "C E Harris"
        },
        {
            "ref_id": "b15",
            "title": "Changing the paradigm for engineering ethics",
            "journal": "Science and Engineering Ethics",
            "year": "2013-11",
            "authors": "J A Schmidt"
        },
        {
            "ref_id": "b16",
            "title": "Culture of disengagement in engineering education?",
            "journal": "",
            "year": "2014",
            "authors": "E A Cech"
        },
        {
            "ref_id": "b17",
            "title": "Swede detained for building nuclear reactor in kitchen",
            "journal": "",
            "year": "2011-08",
            "authors": "D Geere"
        },
        {
            "ref_id": "b18",
            "title": "Forbidding science: some beginning reflections",
            "journal": "Science and Engineering Ethics",
            "year": "2009",
            "authors": "L R Kass"
        },
        {
            "ref_id": "b19",
            "title": "Justifying public participation in technical decision making",
            "journal": "IEEE Technology and Society Magazine",
            "year": "1997",
            "authors": "C Mitcham"
        },
        {
            "ref_id": "b20",
            "title": "",
            "journal": "McGraw Hill",
            "year": "2010",
            "authors": "M W Martin; R Schinzinger"
        },
        {
            "ref_id": "b21",
            "title": "Technology and health care decision making: conceptualizing the process for societal informed consent",
            "journal": "Medical Care",
            "year": "1974-10",
            "authors": "L R Tancredi; A J Barsky"
        },
        {
            "ref_id": "b22",
            "title": "Synthetic biology in space: considering the broad societal and ethical implications",
            "journal": "International Journal of Astrobiology",
            "year": "2012-04",
            "authors": "M S Race; J Moses; C Mckay; K J Venkateswaran"
        },
        {
            "ref_id": "b23",
            "title": "The concept of societal informed consent",
            "journal": "",
            "year": "",
            "authors": "B P Green; M S Race"
        }
    ],
    "figures": [],
    "formulas": [],
    "doi": ""
}